{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rojgi\\AppData\\Local\\Temp\\ipykernel_12616\\1598499687.py:18: UserWarning: Argument 'var_limit' is not valid and will be ignored.\n",
      "  A.GaussNoise(var_limit=(10.0, 50.0), p=0.5),  # Gaussian noise\n",
      "C:\\Users\\rojgi\\AppData\\Local\\Temp\\ipykernel_12616\\1598499687.py:20: UserWarning: Argument 'num_shadows_lower' is not valid and will be ignored.\n",
      "  A.RandomShadow(shadow_roi=(0, 0.5, 1, 1), num_shadows_lower=1, num_shadows_upper=2, shadow_dimension=4, p=0.5),  # Shadows\n",
      "C:\\Users\\rojgi\\AppData\\Local\\Temp\\ipykernel_12616\\1598499687.py:20: UserWarning: Argument 'num_shadows_upper' is not valid and will be ignored.\n",
      "  A.RandomShadow(shadow_roi=(0, 0.5, 1, 1), num_shadows_lower=1, num_shadows_upper=2, shadow_dimension=4, p=0.5),  # Shadows\n",
      "C:\\Users\\rojgi\\AppData\\Local\\Temp\\ipykernel_12616\\1598499687.py:21: UserWarning: Argument 'quality_lower' is not valid and will be ignored.\n",
      "  A.ImageCompression(quality_lower=30, quality_upper=90, p=0.5),  # JPEG compression artifacts\n",
      "C:\\Users\\rojgi\\AppData\\Local\\Temp\\ipykernel_12616\\1598499687.py:21: UserWarning: Argument 'quality_upper' is not valid and will be ignored.\n",
      "  A.ImageCompression(quality_lower=30, quality_upper=90, p=0.5),  # JPEG compression artifacts\n",
      "C:\\Users\\rojgi\\AppData\\Local\\Temp\\ipykernel_12616\\1598499687.py:22: UserWarning: Argument 'max_holes' is not valid and will be ignored.\n",
      "  A.CoarseDropout(max_holes=8, max_height=32, max_width=32, min_holes=1, min_height=8, min_width=8, p=0.5),  # CutOut\n",
      "C:\\Users\\rojgi\\AppData\\Local\\Temp\\ipykernel_12616\\1598499687.py:22: UserWarning: Argument 'max_height' is not valid and will be ignored.\n",
      "  A.CoarseDropout(max_holes=8, max_height=32, max_width=32, min_holes=1, min_height=8, min_width=8, p=0.5),  # CutOut\n",
      "C:\\Users\\rojgi\\AppData\\Local\\Temp\\ipykernel_12616\\1598499687.py:22: UserWarning: Argument 'max_width' is not valid and will be ignored.\n",
      "  A.CoarseDropout(max_holes=8, max_height=32, max_width=32, min_holes=1, min_height=8, min_width=8, p=0.5),  # CutOut\n",
      "C:\\Users\\rojgi\\AppData\\Local\\Temp\\ipykernel_12616\\1598499687.py:22: UserWarning: Argument 'min_holes' is not valid and will be ignored.\n",
      "  A.CoarseDropout(max_holes=8, max_height=32, max_width=32, min_holes=1, min_height=8, min_width=8, p=0.5),  # CutOut\n",
      "C:\\Users\\rojgi\\AppData\\Local\\Temp\\ipykernel_12616\\1598499687.py:22: UserWarning: Argument 'min_height' is not valid and will be ignored.\n",
      "  A.CoarseDropout(max_holes=8, max_height=32, max_width=32, min_holes=1, min_height=8, min_width=8, p=0.5),  # CutOut\n",
      "C:\\Users\\rojgi\\AppData\\Local\\Temp\\ipykernel_12616\\1598499687.py:22: UserWarning: Argument 'min_width' is not valid and will be ignored.\n",
      "  A.CoarseDropout(max_holes=8, max_height=32, max_width=32, min_holes=1, min_height=8, min_width=8, p=0.5),  # CutOut\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is enabled for processing.\n",
      "Applying augmentations to training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [24:45<00:00, 25.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentation complete. Augmented images saved to: D:\\\\WORK\\\\Baybayin App Project\\\\split_sampled_dataset_v1\\\\augmented_train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.core.composition import OneOf\n",
    "from albumentations.augmentations.transforms import ImageCompression\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import optuna\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "\n",
    "# Define augmentation pipeline\n",
    "augmentation_pipeline = A.Compose([\n",
    "    A.Rotate(limit=15, p=0.5),  # Random rotation\n",
    "    A.RandomSizedCrop(min_max_height=(100, 300), size=(640, 640), p=0.5),  # Corrected\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),  # Brightness and contrast adjustment\n",
    "    A.OneOf([\n",
    "        A.MotionBlur(blur_limit=3),  # Motion blur\n",
    "        A.GaussianBlur(blur_limit=3),  # Gaussian blur\n",
    "    ], p=0.5),\n",
    "    A.GaussNoise(var_limit=(10.0, 50.0), p=0.5),  # Gaussian noise\n",
    "    A.Perspective(scale=(0.05, 0.1), p=0.5),  # Perspective warp\n",
    "    A.RandomShadow(shadow_roi=(0, 0.5, 1, 1), num_shadows_lower=1, num_shadows_upper=2, shadow_dimension=4, p=0.5),  # Shadows\n",
    "    A.ImageCompression(quality_lower=30, quality_upper=90, p=0.5),  # JPEG compression artifacts\n",
    "    A.CoarseDropout(max_holes=8, max_height=32, max_width=32, min_holes=1, min_height=8, min_width=8, p=0.5),  # CutOut\n",
    "])\n",
    "\n",
    "# Paths\n",
    "train_dir = r\"D:\\\\WORK\\\\Baybayin App Project\\\\split_sampled_dataset_v1\\\\train\"\n",
    "output_dir = os.path.join(r\"D:\\\\WORK\\\\Baybayin App Project\\\\split_sampled_dataset_v1\\\\augmented_train\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Enable GPU processing with TensorFlow\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    print(\"GPU is enabled for processing.\")\n",
    "else:\n",
    "    print(\"GPU is not available. Falling back to CPU.\")\n",
    "\n",
    "# Apply augmentations for each class folder\n",
    "print(\"Applying augmentations to training data...\")\n",
    "for class_name in tqdm(os.listdir(train_dir)):\n",
    "    class_dir = os.path.join(train_dir, class_name)\n",
    "    if not os.path.isdir(class_dir):\n",
    "        continue\n",
    "\n",
    "    class_output_dir = os.path.join(output_dir, class_name)\n",
    "    os.makedirs(class_output_dir, exist_ok=True)\n",
    "\n",
    "    for image_name in os.listdir(class_dir):\n",
    "        image_path = os.path.join(class_dir, image_name)\n",
    "\n",
    "        # Skip non-image files\n",
    "        if not image_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            continue\n",
    "\n",
    "        # Read image\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            continue\n",
    "\n",
    "        # Transfer image to TensorFlow tensor for potential GPU acceleration\n",
    "        image_tensor = tf.convert_to_tensor(image, dtype=tf.float32)\n",
    "        image_tensor = tf.expand_dims(image_tensor, axis=0)  # Add batch dimension\n",
    "\n",
    "        # Augmentation must still use Albumentations (runs on CPU)\n",
    "        augmented = augmentation_pipeline(image=image)\n",
    "        augmented_image = augmented['image']\n",
    "\n",
    "        # Convert back to numpy for saving\n",
    "        augmented_image = tf.squeeze(image_tensor).numpy().astype('uint8')\n",
    "\n",
    "        # Save augmented image\n",
    "        output_path = os.path.join(class_output_dir, f\"aug_{image_name}\")\n",
    "        cv2.imwrite(output_path, augmented_image)\n",
    "\n",
    "print(f\"Augmentation complete. Augmented images saved to: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 41300 images belonging to 59 classes.\n",
      "Found 11800 images belonging to 59 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Paths to dataset folders\n",
    "train_dir = r\"D:\\WORK\\Baybayin App Project\\split_sampled_dataset_v1\\augmented_train\"\n",
    "val_dir = r\"D:\\WORK\\Baybayin App Project\\split_sampled_dataset_v1\\val\"\n",
    "test_dir = r\"D:\\WORK\\Baybayin App Project\\split_sampled_dataset_v1\\test\"\n",
    "\n",
    "# Image dimensions and batch size\n",
    "IMG_HEIGHT, IMG_WIDTH = 128, 128\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Data augmentation and preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_data = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 14:00:40,511] A new study created in memory with name: no-name-f189eb09-ed5a-4aa7-996c-47ce47fd6895\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]C:\\Users\\rojgi\\AppData\\Local\\Temp\\ipykernel_12616\\3556750993.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2025-01-12 14:45:55,681] Trial 0 finished with value: 0.8888135552406311 and parameters: {'num_conv_layers': 1, 'filter_count': 128, 'kernel_size': 5, 'dropout_rate': 0.2455854343480782, 'learning_rate': 0.0010252894210525947}. Best is trial 0 with value: 0.8888135552406311.\n",
      "  5%|▌         | 1/20 [45:15<14:19:48, 2715.16s/it][I 2025-01-12 15:17:11,550] Trial 1 finished with value: 0.8730508685112 and parameters: {'num_conv_layers': 1, 'filter_count': 128, 'kernel_size': 5, 'dropout_rate': 0.4456145565556354, 'learning_rate': 0.003444719654659217}. Best is trial 0 with value: 0.8888135552406311.\n",
      " 10%|█         | 2/20 [1:16:31<11:06:26, 2221.46s/it][I 2025-01-12 15:47:58,630] Trial 2 finished with value: 0.9182203412055969 and parameters: {'num_conv_layers': 2, 'filter_count': 128, 'kernel_size': 3, 'dropout_rate': 0.32286042702465056, 'learning_rate': 0.0001885140687696002}. Best is trial 2 with value: 0.9182203412055969.\n",
      " 15%|█▌        | 3/20 [1:47:18<9:40:58, 2050.51s/it] [I 2025-01-12 16:12:21,657] Trial 3 finished with value: 0.016949152573943138 and parameters: {'num_conv_layers': 3, 'filter_count': 64, 'kernel_size': 5, 'dropout_rate': 0.3959883982850256, 'learning_rate': 0.0036588226189070154}. Best is trial 2 with value: 0.9182203412055969.\n",
      " 20%|██        | 4/20 [2:11:41<8:04:57, 1818.58s/it][I 2025-01-12 16:35:03,618] Trial 4 finished with value: 0.8936440944671631 and parameters: {'num_conv_layers': 1, 'filter_count': 64, 'kernel_size': 5, 'dropout_rate': 0.4461106368349169, 'learning_rate': 0.00046978808080960544}. Best is trial 2 with value: 0.9182203412055969.\n",
      " 25%|██▌       | 5/20 [2:34:23<6:53:28, 1653.92s/it][I 2025-01-12 16:57:26,503] Trial 5 finished with value: 0.016949152573943138 and parameters: {'num_conv_layers': 3, 'filter_count': 32, 'kernel_size': 5, 'dropout_rate': 0.4304579895612578, 'learning_rate': 0.005419265029134772}. Best is trial 2 with value: 0.9182203412055969.\n",
      " 30%|███       | 6/20 [2:56:45<6:01:14, 1548.17s/it][I 2025-01-12 17:18:21,776] Trial 6 finished with value: 0.9532203674316406 and parameters: {'num_conv_layers': 3, 'filter_count': 32, 'kernel_size': 3, 'dropout_rate': 0.4025075599385404, 'learning_rate': 0.0010900523143829762}. Best is trial 6 with value: 0.9532203674316406.\n",
      " 35%|███▌      | 7/20 [3:17:41<5:14:41, 1452.41s/it][I 2025-01-12 17:40:57,020] Trial 7 finished with value: 0.8964406847953796 and parameters: {'num_conv_layers': 2, 'filter_count': 32, 'kernel_size': 5, 'dropout_rate': 0.23543026246885446, 'learning_rate': 0.0025912997473646502}. Best is trial 6 with value: 0.9532203674316406.\n",
      " 40%|████      | 8/20 [3:40:16<4:44:17, 1421.48s/it][I 2025-01-12 18:16:11,726] Trial 8 finished with value: 0.17144067585468292 and parameters: {'num_conv_layers': 2, 'filter_count': 128, 'kernel_size': 5, 'dropout_rate': 0.3013251155432098, 'learning_rate': 0.0023669985005107795}. Best is trial 6 with value: 0.9532203674316406.\n",
      " 45%|████▌     | 9/20 [4:15:31<5:00:20, 1638.19s/it][I 2025-01-12 18:38:43,152] Trial 9 finished with value: 0.8897457718849182 and parameters: {'num_conv_layers': 1, 'filter_count': 64, 'kernel_size': 5, 'dropout_rate': 0.3640145876428686, 'learning_rate': 0.0010748214576539654}. Best is trial 6 with value: 0.9532203674316406.\n",
      " 50%|█████     | 10/20 [4:38:02<4:18:16, 1549.66s/it][I 2025-01-12 19:00:03,449] Trial 10 finished with value: 0.9522881507873535 and parameters: {'num_conv_layers': 3, 'filter_count': 32, 'kernel_size': 3, 'dropout_rate': 0.47650900090377657, 'learning_rate': 0.00013217908710687926}. Best is trial 6 with value: 0.9532203674316406.\n",
      " 55%|█████▌    | 11/20 [4:59:22<3:40:04, 1467.22s/it][I 2025-01-12 19:21:02,874] Trial 11 finished with value: 0.9509322047233582 and parameters: {'num_conv_layers': 3, 'filter_count': 32, 'kernel_size': 3, 'dropout_rate': 0.49715292706102504, 'learning_rate': 0.00013075885181221953}. Best is trial 6 with value: 0.9532203674316406.\n",
      " 60%|██████    | 12/20 [5:20:22<3:07:12, 1404.01s/it][I 2025-01-12 19:41:48,571] Trial 12 finished with value: 0.95313560962677 and parameters: {'num_conv_layers': 3, 'filter_count': 32, 'kernel_size': 3, 'dropout_rate': 0.48385543779189355, 'learning_rate': 0.0003752114241142856}. Best is trial 6 with value: 0.9532203674316406.\n",
      " 65%|██████▌   | 13/20 [5:41:08<2:38:12, 1356.05s/it][I 2025-01-12 20:02:30,224] Trial 13 finished with value: 0.9515254497528076 and parameters: {'num_conv_layers': 3, 'filter_count': 32, 'kernel_size': 3, 'dropout_rate': 0.39408076927239744, 'learning_rate': 0.0004129600570135699}. Best is trial 6 with value: 0.9532203674316406.\n",
      " 70%|███████   | 14/20 [6:01:49<2:12:08, 1321.50s/it][I 2025-01-12 20:23:22,678] Trial 14 finished with value: 0.9528813362121582 and parameters: {'num_conv_layers': 3, 'filter_count': 32, 'kernel_size': 3, 'dropout_rate': 0.41283462190462333, 'learning_rate': 0.00046701053860910904}. Best is trial 6 with value: 0.9532203674316406.\n",
      " 75%|███████▌  | 15/20 [6:22:42<1:48:23, 1300.69s/it][I 2025-01-12 20:44:08,213] Trial 15 finished with value: 0.9161016941070557 and parameters: {'num_conv_layers': 2, 'filter_count': 32, 'kernel_size': 3, 'dropout_rate': 0.35570958320650414, 'learning_rate': 0.00029381538771312084}. Best is trial 6 with value: 0.9532203674316406.\n",
      " 80%|████████  | 16/20 [6:43:27<1:25:36, 1284.08s/it][I 2025-01-12 21:06:20,606] Trial 16 finished with value: 0.95245760679245 and parameters: {'num_conv_layers': 3, 'filter_count': 32, 'kernel_size': 3, 'dropout_rate': 0.47323761537322157, 'learning_rate': 0.0013427681070024397}. Best is trial 6 with value: 0.9532203674316406.\n",
      " 85%|████████▌ | 17/20 [7:05:40<1:04:55, 1298.61s/it][I 2025-01-12 21:32:49,302] Trial 17 finished with value: 0.016949152573943138 and parameters: {'num_conv_layers': 2, 'filter_count': 32, 'kernel_size': 3, 'dropout_rate': 0.2865996858484806, 'learning_rate': 0.009506793462065111}. Best is trial 6 with value: 0.9532203674316406.\n",
      " 90%|█████████ | 18/20 [7:32:08<46:11, 1385.78s/it]  [I 2025-01-12 21:57:36,837] Trial 18 finished with value: 0.9540678262710571 and parameters: {'num_conv_layers': 3, 'filter_count': 32, 'kernel_size': 3, 'dropout_rate': 0.3771711165370456, 'learning_rate': 0.0006246382625851964}. Best is trial 18 with value: 0.9540678262710571.\n",
      " 95%|█████████▌| 19/20 [7:56:56<23:36, 1416.34s/it][I 2025-01-12 22:25:20,742] Trial 19 finished with value: 0.9543220400810242 and parameters: {'num_conv_layers': 3, 'filter_count': 64, 'kernel_size': 3, 'dropout_rate': 0.37737044764714117, 'learning_rate': 0.0014360029060797065}. Best is trial 19 with value: 0.9543220400810242.\n",
      "100%|██████████| 20/20 [8:24:40<00:00, 1514.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'num_conv_layers': 3, 'filter_count': 64, 'kernel_size': 3, 'dropout_rate': 0.37737044764714117, 'learning_rate': 0.0014360029060797065}\n",
      "Best Epoch: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Hyperparameters to tune\n",
    "    num_conv_layers = trial.suggest_int(\"num_conv_layers\", 1, 3)\n",
    "    filter_count = trial.suggest_categorical(\"filter_count\", [32, 64, 128])\n",
    "    kernel_size = trial.suggest_categorical(\"kernel_size\", [3, 5])\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.2, 0.5)\n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
    "\n",
    "    # Build CNN with dynamic hyperparameters\n",
    "    for _ in range(num_conv_layers):\n",
    "        model.add(Conv2D(filter_count, (kernel_size, kernel_size), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)))\n",
    "        model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(train_data.num_classes, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    " # Track the best validation accuracy and corresponding epoch\n",
    "    best_epoch = 0\n",
    "    best_val_accuracy = 0.0\n",
    "\n",
    "    for epoch in range(1, 31):  # Iterate through 1-30 epochs\n",
    "        history = model.fit(\n",
    "            train_data,\n",
    "            epochs=1,\n",
    "            validation_data=val_data,\n",
    "            verbose=0\n",
    "        )\n",
    "        val_accuracy = history.history['val_accuracy'][0]\n",
    "\n",
    "        # Update the best validation accuracy and epoch\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_epoch = epoch\n",
    "\n",
    "    # Log the best epoch for this trial\n",
    "    trial.set_user_attr(\"best_epoch\", best_epoch)\n",
    "    return best_val_accuracy\n",
    "\n",
    "# Run Optuna optimization with progress bar\n",
    "class TQDMOptunaCallback(optuna.integration.TFKerasPruningCallback):\n",
    "    def __init__(self, iterator):\n",
    "        self.iterator = iterator\n",
    "\n",
    "    def __call__(self, study, trial):\n",
    "        self.iterator.update(1)\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "with tqdm(total=20) as pbar:\n",
    "    study.optimize(lambda trial: objective(trial), n_trials=20, callbacks=[TQDMOptunaCallback(pbar)])\n",
    "\n",
    "# Get the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", study.best_params)\n",
    "print(\"Best Epoch:\", study.best_trial.user_attrs[\"best_epoch\"])\n",
    "\n",
    "# Build and train the final model with best hyperparameters\n",
    "best_params = study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EPOCH NOT the OPTIMAL YET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/27\n",
      "1291/1291 [==============================] - 59s 45ms/step - loss: 1.0279 - accuracy: 0.7210 - val_loss: 0.4644 - val_accuracy: 0.8635\n",
      "Epoch 2/27\n",
      "1291/1291 [==============================] - 54s 42ms/step - loss: 0.4057 - accuracy: 0.8749 - val_loss: 0.3560 - val_accuracy: 0.8975\n",
      "Epoch 3/27\n",
      "1291/1291 [==============================] - 59s 46ms/step - loss: 0.2890 - accuracy: 0.9087 - val_loss: 0.2792 - val_accuracy: 0.9195\n",
      "Epoch 4/27\n",
      "1291/1291 [==============================] - 57s 44ms/step - loss: 0.2174 - accuracy: 0.9299 - val_loss: 0.2512 - val_accuracy: 0.9311\n",
      "Epoch 5/27\n",
      "1291/1291 [==============================] - 55s 42ms/step - loss: 0.1733 - accuracy: 0.9446 - val_loss: 0.2477 - val_accuracy: 0.9349\n",
      "Epoch 6/27\n",
      "1291/1291 [==============================] - 53s 41ms/step - loss: 0.1504 - accuracy: 0.9506 - val_loss: 0.2347 - val_accuracy: 0.9381\n",
      "Epoch 7/27\n",
      "1291/1291 [==============================] - 53s 41ms/step - loss: 0.1255 - accuracy: 0.9588 - val_loss: 0.2456 - val_accuracy: 0.9375\n",
      "Epoch 8/27\n",
      "1291/1291 [==============================] - 54s 42ms/step - loss: 0.1138 - accuracy: 0.9622 - val_loss: 0.2447 - val_accuracy: 0.9382\n",
      "Epoch 9/27\n",
      "1291/1291 [==============================] - 51s 39ms/step - loss: 0.0970 - accuracy: 0.9672 - val_loss: 0.2468 - val_accuracy: 0.9419\n",
      "Epoch 10/27\n",
      "1291/1291 [==============================] - 51s 40ms/step - loss: 0.0892 - accuracy: 0.9698 - val_loss: 0.2525 - val_accuracy: 0.9397\n",
      "Epoch 11/27\n",
      "1291/1291 [==============================] - 52s 40ms/step - loss: 0.0787 - accuracy: 0.9734 - val_loss: 0.2707 - val_accuracy: 0.9458\n",
      "Epoch 12/27\n",
      "1291/1291 [==============================] - 52s 40ms/step - loss: 0.0717 - accuracy: 0.9756 - val_loss: 0.2785 - val_accuracy: 0.9432\n",
      "Epoch 13/27\n",
      "1291/1291 [==============================] - 51s 40ms/step - loss: 0.0660 - accuracy: 0.9777 - val_loss: 0.2774 - val_accuracy: 0.9458\n",
      "Epoch 14/27\n",
      "1291/1291 [==============================] - 52s 41ms/step - loss: 0.0600 - accuracy: 0.9808 - val_loss: 0.2701 - val_accuracy: 0.9446\n",
      "Epoch 15/27\n",
      "1291/1291 [==============================] - 50s 39ms/step - loss: 0.0557 - accuracy: 0.9818 - val_loss: 0.2825 - val_accuracy: 0.9475\n",
      "Epoch 16/27\n",
      "1291/1291 [==============================] - 52s 40ms/step - loss: 0.0535 - accuracy: 0.9827 - val_loss: 0.2666 - val_accuracy: 0.9502\n",
      "Epoch 17/27\n",
      "1291/1291 [==============================] - 51s 39ms/step - loss: 0.0498 - accuracy: 0.9838 - val_loss: 0.2830 - val_accuracy: 0.9481\n",
      "Epoch 18/27\n",
      "1291/1291 [==============================] - 50s 39ms/step - loss: 0.0463 - accuracy: 0.9848 - val_loss: 0.2783 - val_accuracy: 0.9484\n",
      "Epoch 19/27\n",
      "1291/1291 [==============================] - 51s 39ms/step - loss: 0.0436 - accuracy: 0.9859 - val_loss: 0.2784 - val_accuracy: 0.9495\n",
      "Epoch 20/27\n",
      "1291/1291 [==============================] - 52s 40ms/step - loss: 0.0418 - accuracy: 0.9863 - val_loss: 0.2701 - val_accuracy: 0.9520\n",
      "Epoch 21/27\n",
      "1291/1291 [==============================] - 51s 39ms/step - loss: 0.0411 - accuracy: 0.9864 - val_loss: 0.2996 - val_accuracy: 0.9479\n",
      "Epoch 22/27\n",
      "1291/1291 [==============================] - 51s 40ms/step - loss: 0.0387 - accuracy: 0.9873 - val_loss: 0.2708 - val_accuracy: 0.9504\n",
      "Epoch 23/27\n",
      "1291/1291 [==============================] - 61s 47ms/step - loss: 0.0354 - accuracy: 0.9887 - val_loss: 0.2976 - val_accuracy: 0.9499\n",
      "Epoch 24/27\n",
      "1291/1291 [==============================] - 92s 71ms/step - loss: 0.0354 - accuracy: 0.9890 - val_loss: 0.3094 - val_accuracy: 0.9522\n",
      "Epoch 25/27\n",
      "1291/1291 [==============================] - 83s 64ms/step - loss: 0.0351 - accuracy: 0.9893 - val_loss: 0.3393 - val_accuracy: 0.9497\n",
      "Epoch 26/27\n",
      "1291/1291 [==============================] - 97s 75ms/step - loss: 0.0323 - accuracy: 0.9903 - val_loss: 0.3369 - val_accuracy: 0.9505\n",
      "Epoch 27/27\n",
      "1291/1291 [==============================] - 96s 74ms/step - loss: 0.0281 - accuracy: 0.9910 - val_loss: 0.3335 - val_accuracy: 0.9475\n",
      "Found 5900 images belonging to 59 classes.\n",
      "185/185 [==============================] - 9s 49ms/step - loss: 0.3366 - accuracy: 0.9466\n",
      "Test Loss: 0.3366023004055023, Test Accuracy: 0.946610152721405\n"
     ]
    }
   ],
   "source": [
    "final_model = Sequential()\n",
    "for _ in range(best_params[\"num_conv_layers\"]):\n",
    "    final_model.add(Conv2D(best_params[\"filter_count\"], (best_params[\"kernel_size\"], best_params[\"kernel_size\"]), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)))\n",
    "    final_model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "final_model.add(Flatten())\n",
    "final_model.add(Dropout(best_params[\"dropout_rate\"]))\n",
    "final_model.add(Dense(train_data.num_classes, activation='softmax'))\n",
    "\n",
    "final_model.compile(optimizer=Adam(learning_rate=best_params[\"learning_rate\"]), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "final_model.fit(\n",
    "    train_data,\n",
    "    epochs=study.best_trial.user_attrs[\"best_epoch\"],\n",
    "    validation_data=val_data\n",
    ")\n",
    "\n",
    "# Save the final model\n",
    "final_model.save(\"version2Testing.h5\")\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "test_data = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "results = final_model.evaluate(test_data)\n",
    "print(f\"Test Loss: {results[0]}, Test Accuracy: {results[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5900 images belonging to 59 classes.\n",
      "185/185 [==============================] - 8s 40ms/step - loss: 0.3366 - accuracy: 0.9466\n",
      "Test Loss: 0.33660224080085754, Test Accuracy: 0.946610152721405\n",
      "185/185 [==============================] - 7s 35ms/step\n",
      "Accuracy: 0.9466101694915254\n",
      "Precision: 0.9481945840848515\n",
      "Recall: 0.9466101694915253\n",
      "F1-Score: 0.9464724878204224\n",
      "AUC: 0.9990359438924605\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load test data\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "test_data = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Evaluate model\n",
    "results = final_model.evaluate(test_data)\n",
    "print(f\"Test Loss: {results[0]}, Test Accuracy: {results[1]}\")\n",
    "\n",
    "# Predictions and true labels\n",
    "y_true = test_data.classes\n",
    "y_pred = final_model.predict(test_data)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_true, y_pred_classes)\n",
    "precision = precision_score(y_true, y_pred_classes, average='macro')\n",
    "recall = recall_score(y_true, y_pred_classes, average='macro')\n",
    "f1 = f1_score(y_true, y_pred_classes, average='macro')\n",
    "\n",
    "# One-hot encoding for AUC\n",
    "y_true_one_hot = to_categorical(y_true, num_classes=len(test_data.class_indices))\n",
    "auc = roc_auc_score(y_true_one_hot, y_pred, multi_class='ovr')\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-Score: {f1}\")\n",
    "print(f\"AUC: {auc}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
